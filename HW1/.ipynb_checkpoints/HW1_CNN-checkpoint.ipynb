{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826aaf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, MSELoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fedb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>views</th>\n",
       "      <th>country</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normalize_5s_intro_thc1MtNagC8.wav</td>\n",
       "      <td>38319601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalize_5s_intro_Wo2qUD1g7xM.wav</td>\n",
       "      <td>71940972</td>\n",
       "      <td>VN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalize_5s_intro_3ObVN3QQiZ8.wav</td>\n",
       "      <td>28548855</td>\n",
       "      <td>FR</td>\n",
       "      <td>0.447368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normalize_5s_intro_S-zQJFRX5Fg.wav</td>\n",
       "      <td>310197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normalize_5s_intro_SyZOAgXiPMw.wav</td>\n",
       "      <td>1283578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                track     views country     score\n",
       "0  normalize_5s_intro_thc1MtNagC8.wav  38319601     NaN  0.676471\n",
       "1  normalize_5s_intro_Wo2qUD1g7xM.wav  71940972      VN  0.666667\n",
       "2  normalize_5s_intro_3ObVN3QQiZ8.wav  28548855      FR  0.447368\n",
       "3  normalize_5s_intro_S-zQJFRX5Fg.wav    310197     NaN  0.876712\n",
       "4  normalize_5s_intro_SyZOAgXiPMw.wav   1283578     NaN  0.325000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3dbbd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 220/220 [00:02<00:00, 109.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(220, 28, 28, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading training images\n",
    "train_img = []\n",
    "for img_name in tqdm(train['track']):\n",
    "    # defining the image path\n",
    "    image_path = './img/' + str(img_name) + '.jpg'\n",
    "    # reading the image\n",
    "    img = imread(image_path)\n",
    "    img = resize(img, (28, 28))\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # normalizing the pixel values\n",
    "    #img /= 255.0\n",
    "    # appending the image into the list\n",
    "    train_img.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "train_x = np.array(train_img)\n",
    "# defining the target\n",
    "train_y = train['score'].values\n",
    "\n",
    "#print(train_x)\n",
    "#print(train_y)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e905432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AxesSubplot:>, <matplotlib.image.AxesImage at 0x1b8c40f0488>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAI/CAYAAABj+03oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABT20lEQVR4nO3dWYxl213n+d9/nzlODBmR080728ZQZeiuS1WWq7qgaVdT0IYuteHFwg/IJaG+PGAJJNRdyFI3finJKjFUPZSQTNmyW2JoJExhlUyB20JyoW4Q1y63pwvYmDslOU8xnnGvfsi46sTsXL+VEZEx3Pv9SFc385yVa6+99trr/OOciF9ESkkAAAD4m6qjHgAAAMBxRJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADdqHebCl/lI6vXQ622bz7tj2046wbSrTZDSvbR8Fh9G4ntk2Sf5Y7fCXYp58P/1q/5d0ez6xbUrmZlB1bZtR0fz5NsOqn31+UhB1URWc1Kye2zZz+TYl17suGHOvyn+dUxLwMa4L7gXz/Kje0LQeFayKk2uhv5hODfP71/rdbdtPXXBVkmlTMtHzNLVtepG/byQV7F5SXbDmS8bTNeMpWc+z5Pevkp6q6Pg2BVeiZG46Zj+YJt9HyVhK5qYbA9umLlgVJcdyI46CfTIKzntuXkOm9bbm9aSxo329okbEuyX9W0ktSf8+pfThXPvTS6f1v73nf8/2+Ue/90173HO9lm3TM1XSn234zazd8gvzldEN22ZSj2yb1U5+85Wk9fmObfN3zSZeskH/l/VXbJt+weL9rqUnbJs/375p24ySn+N/uPiO7POvjvzcLbb9pnhrvGnb3K7v2DZnOmdsm625/4Lh24ZL2edHfgnrpZ0t26ZrCsjP3/2kP9Ax9DB72Knhaf3kD30w29/v/d5/scccFewHU+VfYFoFLwwb9XXb5q2d77BtduZ+EY3SXdvm9vyKbfNk6+9mn59Vfiw3Zq/aNlHwBedi+5xt0wv/heBWvW7bPNHN7wdXZr6PQcEHQzdnl2ybZ9rfadtsJv/6ebPgOrTMvtKuTtk+etGzbe6m/OvMK5ufe+Bze/64LSJakv6dpB+S9A5J74uI/CsVABwT7GEAnP18T9I7JX0jpfTNlNJE0m9Kes/BDAsAHjn2MABZ+ymSnpB0//tpr+0+BgAnAXsYgKxH/tNtEfF8RLwQES9s7Pjv5wCA4+L+/Wt7xP4FvNnsp0i6JOmp+/7+5O5jf0NK6SMppYsppYtLg8V9HA4ADpTdw+7fvxb67F/Am81+iqQ/lfT2iHhLRHQl/ZikTx3MsADgkWMPA5C15wiAlNIsIj4g6fd178dnP5ZS+mr+30hj86OXmyUZPf4no7XScT8W6H+EtuPCliRVBblE2/WGbbOiU7ZNSU7Slvnx4mlB6MlY/keUe7Fg25TMX0leSbsgrySZ6zktyFoa134s68n/KO6V6Uu2zbDlf2x1mvx5Xx/ns2cGBT8eW5Iz0qvy/VRx8nJpH3YPC/mvKrsFW2qSvyYu86Ys78YfZ7Hya6xOfn2Mkj/vTvKZTC6rrCrKNyqIiCnYv1ryP96vKNm/CubGtBkUrJmU/B6ngmtZks/m9ltJarf89ZbJf3L5RpJUFWR99ZTPforMnb2vnKSU0qclfXo/fQDAUWEPA5Bz8r78AwAAOAQUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKDBvnKSHlYV0kIrX5etdn2A15rPP9O5Xj7sanPmA8c6LR+q1TXhZ5J0pr1q25zt+F95UCU/5tVWPiRtHPnwrnt9LNs2JQFp7YKAwYXKn/dm7YPzWqbeHxQEUi61fZutuQ+hu26CF6WyMMluQZjdcjsfpNYrOO+VgnMatvLXu1UQLnfShaSuCUjtFGypI/n1XCl/3bol4Z0FQYedgvXRTf5YJXtTXRcEA5rXh1ZBaGVJqOK0YL0uyJ9TKgigncvvuS0znKrg/Yx8rOw9ndbQj8VcA6nsvKcF16Fjgj9L1mdJGK6/Bg8+H95JAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADQ41DDJe2Fs+RCqqiDs8M7Mx2ad7eYD8joF9eGw5YOsznZ98OL1SW3bLFYFQYYmyE6SelU+nGup7UMMn5xfsG225/4aDAtCyc60B7ZNZ75k2yx18sdamvnjnCq43uOOv5an5udsm3Mdv25aJihSkhbb+es9bPs10zXBhZI0MMfpVG/8r7eqCPXNeT7W9eGoC1MfEuqC+HaSD6TshT9OSShsqyCUcii/Vqu2vy+Wqnw/2wXBst3w4aguxFCSegVzEyVBm+HXRNeEJnbC77dVwXUa1/5eH1Z+3cyT3we3kj+WC8lcqFZsH+41T5J26lH2+ciM442/swEAAOwBRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABocKg5SVUkDVv5HKSSbJ2S2m6lmz/O6Z4/9W7lM5t64ccSyR9rIp9x0QmfebNgIiMWWr6PlYK8oGFBzsj5nm8zn/tMjsHU93PK5AGtt/01WCm4GyYF2R8rrVXbpiqYv6cG/ljTeX7dnO4WZNz4oWjT3Apvlq+23C3YK8iLOlWQfzU1OTT9uc87Gye/f3XlL/5CQT5bS0Pbpl2wD3ZM5k1f/rwXtWbbVMnfFz35vSkVzE0V/nq3zEtx2+QoSVKvIO9sWvCa1lLJOfk2/ZbPh6pMztQwfL5dQRSchuYaVJlzfrPsbQAAAA+FIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABocKhhkp1KOr8wy7Z57pQP+dqZ+dCsZ5am2ecncx+i1m3lA93uWbAtOgUBhI/1/aXYKgiCPN/Lj7lb+fm9OfFjSfJzc86MRZLaBaGKSxMf6na2nw9JuznxXw+c95lvOjvwYXa96jHbZljw5cli289fxyyt0wXXYGPmB9PO37YqyoA94aqQljr5Ez0/KAiOnZXsK/nj7BTsX+O5P06v8uOdJXPxJW3N/L5S8jX5tM6P2T0vSe2CEEhzGe8dK+VfQySpIJNS4zSybbbr/HW4W2/aPmYFxxmlu7bNmfBhnNv12La5Pbtu23Qiv5+2VRBIWXA73Yo72ednevDrx5tgawMAAHh4+3onKSJekrQhaS5pllK6eBCDAoDDwB4GIOcgPm77pymlGwfQDwAcBfYwAI34uA0AAKDBfoukJOkPIuLzEfH8QQwIAA4RexiAB9rvx23fm1K6FBHnJH0mIv4spfS5+xvsbjzPS9JjS/675gHgEGX3sPv3r9OLp49qjACOyL7eSUopXdr9/zVJvyPpnQ1tPpJSuphSunhqwf84HwAcFreH3b9/LfbZv4A3mz0XSRExjIil1/8s6QclfeWgBgYAjxJ7GABnPx+3nZf0OxHxej+/nlL6T7l/EJHUMal0BZmK2vTZZuq38uGCK73885LUCp8U9rjPktTO3IdJFuRE6u7Uj3lnnu+oXxCQudzyQXWdlr9Qpxd8AFq74HpXBYGTZ/v5a3V15Ce4JBCx5KuK5bZvtVh05/kxr/XygXcrXb9mFH4wq738TdcrCCk9hh56D0vKn2dVELJacEVUJXMfV35tdMK36flbS3XBqk/ySazTgiXSNmMuGa98BqTq2g+mX7DHFQ2nIEz4dCc/fy50UZKqgterzan/lpeVtj/WoOCcegXlxTjyoZR+JNKw5cNDF9PT2ecvx4P72HORlFL6pqS/t9d/DwBHiT0MgEMEAAAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANBgv7+77aG1TBhbxzwvSbPk29QmiG8280Fr3b4PhhvGxLZZ7PrIMReiJkmnCvoZdvKhf2875cfbq3ww3N2ZvwbTua/BbxeEPN6e+Pi91W6+n2HHH+eJYT7YTJKSCfmTpJ1ZQdBaQXroYtuf91OL+TF3Kr+G1wY+fW9gQil7BSGlJ11K0mSeX/dbBfvKRsF6rszXr1GwX0RBGGm7IIBwXJJHWjCe6dx3lEw/o9r3MZK/jxUFJ1X7KMNuQdBtpyrY/831vjvdsn3MC4JMxxrZNovJ//qdWcHtvlNwHSa1G4+fu1QQzxpmfnMlBe8kAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABocaphkSqGxCdqrCkLJznV9bZfm+VDF21MfUjXyOWu6NfFjubrjO1ps+/OeF4TDTUzY4fbMX/LbU39OUxOqJ0mz2s9xqyCMrSBDU7UJGN3JLwdJ0tUdHwK57rM49dq2b7PYKVhcBWGmG5P89Tzd80GRLnhVkq5t5IP1ZrXv46SLkHotc93Cz3e/7a9rSvnrOk/+HnX3hCRNijJASxr5QL86fLjgsD3MH2VacN8kP95OVRAmXBBk2Eq+zawgADOZUE8XhiiVXe+S/bYg51abtd9QuwXlRTvy17sXg4I+/NxMajc3Dz5p3kkCAABoQJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANDjUMMmIpF4rH7bWa/vgrakNhpKilQ8UmxcEpG1NfapWqyDAa1BQivbNeCVpZ14wHhMMOJ8VBG/5S6Cdgjbdyp/T2Z4PJSsJUlvp5Ad0abtr+xgXnNOkIDSxZG76LX9OtwrSTPsmGy7CX4Np7ccyNkOZmxDTN4q5uf6Tecn9tf/7OMmvjbrgmhREM6oqCFVUwT5YFdzHLiuyJDhwEH3bpl0QoFpy3p2qIJyx4LwrM57l1oLtw+0FkhTy+21V+fEOC8JMF9KKbbNhQp97BSVKyV66E/nj5LJFeScJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0OBwwySVVLXyaWGz5JP4xgVBVm2TJ/bYwB8nCpLWZgXhgp2CgMxBQRBYJzq2zVI7H9bZKQh4XO35wSwVBNUNuv68O3M/yYvJj+fUMH/ep0Z+qa/1/HiXu36849of68KCD3UbFFyrQSffptPx4527BD9J7blfe28GVZWfq5Wuvy+2p37/cnm5URIDWZDv2S34MnlcEN67ECWhf75NmDFPCk4qyQfHFr07UDB/7VwK4evHKrhUC+18PyO/Xdg+JGlrWhB+WfD6utz213Jj6vevvnlNK5nfWUGQ6bzOjyXXhZ2NiPhYRFyLiK/c99haRHwmIr6++/9VO0oAOALsYQD2qqSg/rikd3/LYz8n6bMppbdL+uzu3wHgOPq42MMA7IEtklJKn5N061sefo+kT+z++ROSfuRghwUAB4M9DMBe7fUbt8+nlC7v/vmKpPMHNB4AOAzsYQCsff90W0opKfPLpCPi+Yh4ISJeuL29td/DAcCByu1h9+9fm6ONQx4ZgKO21yLpakRckKTd/197UMOU0kdSShdTShdXF4Z7PBwAHKiiPez+/Wuxv3SoAwRw9PZaJH1K0vt3//x+Sb97MMMBgEPBHgbAsmEHEfEbkt4l6UxEvCbp5yV9WNJvRcRPSHpZ0nvLDhcKEz6xUJAXNGn5/IWWyVuqCnJGxgX5FnVBP4OCiJmByY+SpNHcn3evZfI2CvKNQv44nYIMkVbBObUKsoCGPr5IY9NNtyCsJBXkg4xrP5gFk1UlSQvmOkmy94okTU2GTUHMiOYFa2JkTrsgquTIHNQelpI0mufn6vKOD7QxkS2SpEWTQ7M9K7i3Cq591fFrfnvuzykK7p150SLJD7ok16kk4G6aCl5DCu6/UV2Sd1aQi1Xn29ye79g+NuuCDCQVZODZFtK0IB9wu2BubtX5b8GpCnL0qvDnNNY4+/xcD97gbJGUUnrfA576fvdvAeCosYcB2Ct+LQkAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABoQJEEAADQwOYkHaiQXN5VdAqCDAuCrNyZPbGaD5eSpLs7PqRq2PfjHReEknV87pZqExwoSQOT8nhuWDC/LT+Yq5t+6WxO/PzV4Y81Kciga8/y5z0tCPCLygdFPrHs25wuuJaa+bnZmvoTb5u1lcy8SNJyx5+Ty0MtCS486SJ8iOpapyDQL/zXpi5ItFcQmJjCX5SSsNFO+Hu9INuyKKTWTU1VEMzYLghHHRSEFpes6Y2CEy/I61TL7D2TNLF9tMOnFo8LQjQXC673qYLX6e2C16sw4aytghKlZG5yYZGSlDKh0LyTBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhwqGGS8zq0sZ0PvPrKjb7t59q2T/n6zkn+OEt9n/jXbvs22z7HSttTP95UEJA5qn2A16DKt5kXhNCV6BckpM3nPrHtzrggqK5gbuYmR21S0EevIExyPPVtbo/9HFfJz9/dgrk5PZhmn58XBIMWZO9pYIZSHdC6Os5CUtdctk7Lz8NoVpBsasxLLlpBmN9C2/czrf0a2pn7Y3UL0hldEORo7scyLggXnJkQQ0kaF8yfCymUpLf2/D64YJpUyfexPvNzM6z8nrIz8+c08k00aPlwS7fnpoLwy566tk3fxOG29OD55Z0kAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQINDDZNMSZqYEK9Oy6dUPb7oA6amdb7+e/HGwPbR6fhQssHC2LaZFwRijWc+uOzytj/Wuglw3Jz54K072752ns780jG5lpKk7bk/VsHUqGcONjHrQZKu7Pi52dG2bbM+zQc8SlK/4M4bF4SHVnMTxlYQmjeZ+qA6jfNzMy4I6zzpqkhaaOevSbcgvHPLN9GGW/S1D+pTQWBpQc6houDSVpW/STuV72ixlR9zSQxnt+7ZNqGCgN+Zv497BeGM6ybYWJLOL+XP7OnB0Pbx+IK/BoOCQM+duT+njam/EjcnBfugWaL9yl/LecE+6dZwK9OAd5IAAAAaUCQBAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADQ41TLJd1To3zAciDtd8gONBmBSEsfVNcJwk3R77fgoy1NQuCONbavVtm2UTxjmb+sCxee2XRbegvF7o+DCxjZkPC2sVRMi1TJjk9tQPuFtwoeq0YNv0C8a7WhDit1Uwnsd6+TZnev5+Goe/3nfq/LopWeMn3SxJt8x0fu1OwXwXhN+lKn8fD8LvBf2C61qFD1AtCV6U/L6yXhDO6DIKBy1/41Thx3Kq66/Bs0PfzyT58WxO/LFGJux2VpCiuTX11+nytj+nVLB/nTP7jiR957Kfm3PjfKjz1szv29s+f1p3p/kE19watyOIiI9FxLWI+Mp9j30oIi5FxBd3//thP0wAOHzsYQD2quTjto9LenfD47+cUnpu979PH+ywAODAfFzsYQD2wBZJKaXPSbp1CGMBgAPHHgZgr/bzjdsfiIgv7b6VvXpgIwKAw8EeBiBrr0XSr0h6m6TnJF2W9IsPahgRz0fECxHxwu3trT0eDgAOVNEedv/+tbmzeYjDA3Ac7KlISildTSnNU0q1pF+V9M5M24+klC6mlC6uLgz3Ok4AODCle9j9+9fiYPFwBwngyO2pSIqIC/f99UclfeVBbQHguGEPA1DCBmlExG9IepekMxHxmqSfl/SuiHhO98IxXpL0k49uiACwd+xhAPbKFkkppfc1PPzRvRwsKTSZ50Oorm37ALR+1wdiPbY6yj7/nb1128d4VBAUdjMfhiVJ997Rz+u0/Jt6Cy0/N2uD/Nx0C4LW2uHHEgXhZksdf6yb43zIlySNC8LCZM7rLUu+k9W+D7u7OfVr4mZBHmqv8nPT6/s2q938eU0LxlsSbrhsQilbBevqqBzUHlZFaKGT37++fdmHM44Kgk03zXLdKEgXrMOv+Z2Caz9J/h6dqWDRm8BXSQoTgNkp6GOefNBhyZ6yqYKg4IIPY9a6fjwtc/tMC67BlfxLniRpNPfzd77v1/CG3yp1Y+Tn5tY0fyHGyR9oVvD6Ojdhp7nn+bUkAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAY+nfAgRZLa+VCnlnlekmYFYWEbW/lArOsb/tTPPeYD0pblQ77S1LdZXfDnNCoIXrxwLj/mee3r4t6Ovwa3r/p+Tp8e2zZrp30C2uaOn5ulfj5Q7Mrtvu3j9IoPLltZ9uGM50Z+vL2CMMDpqCBM8nS+zaQgYK5dEAx6+0b+ehd0ceJVSuqb0Mzljk8pnNW+zUD5NTRPvo92wZfAiwWvANsz32iQ/H1Rq2TM+fmdFoQL3pz7oODWzAcmnmr5PeNsz5/3LPkLsWhCSlUQ1rlQcC0HBW2eHfoQzZIwybsmKFKSzlX5uRnVBa+LBQGZivx16mQClHknCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhwqDlJVRVaWM7nHjz2lM9WSCZDRJJaJrmlM/F9DAuyi97+bX4K05Ztos7Mn/d822dl9M1w6tM920fcsk20ft3X19tzPzfV0J93tyB7Jpm8jZ2CfKg6k5XxuuEp3ybd8flGnYL8jzDnJEmd0/k2w5bPEOnd8vPbr/PBKJ2WP+eTLqXQdJ6f79sjn7+z4ePONGjl18fblvz6Gfgm2vSXXoOOX4dRkAW0M/OZQmfM9BVE5KkzX7JtLvR8R6d7/pxu7vhz6hbcx2Hyt54syC76u6f9wrq56ffkOvl7+allv3Bi3fdzd5a/DpOCbaVTFdQDkW+Te5Z3kgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANDjVMMiVpPM3XZVfWfWhWPfMBeR1T/40KUsm+/pc+ePG1F32dOS4IVTzV8aFk84LgtyeG+UCx6Td8OtedkR/LQL6f7tyHm9255a/DYt82kcn40/bYn9PLV/213Ljsx7s5LQiKLFh/07lvc+FaPuTxmTUfQLozKfhaaZZfw7W/JU+8CKltllG3U3Bdp36ytkyK3u2ClL3Vjt93lgqCIqczf6x5KggXtC2k2uzbqSDoME39a8jdgvvvyqa/TnXBPvgPLuzYNgMTOHn7ln8tevGGv953xv68q8qf09MF4aH9tl8T182+3C5YNKlgvKM6/1qUMteRd5IAAAAaUCQBAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADQ41TFKSKhO+Na99MNTGyCdMLZkUqlx41OvOnMoH9UnS9l0fmNUZ+FDFxYJArPVNH4jYN/2kgmC48yt+vAWnpFlBGOJ46pfgVkE4XN90c27gr+Vi35/UX2/78XZaPoTuzLJvM/ND1sBc76W27+RUx6+J8Tj/9VSrYP2edFUkLZqAvPMLPrxzMu3aNnPl18dCQcpep/J702rJtS8IXmwVhAuW5I12In+sbuXH0g1/Tqd6fjSbJvhYkuqCudna8dd7ZSm/bgZtP947k4IgU/n9YKXy++12wb5dEgRZ1/k1OirYVkamD0naTqPs8/P04Pm1qyAinoqIP4yIr0XEVyPip3cfX4uIz0TE13f/v2pHCgCHiP0LwH6UfNw2k/SzKaV3SPrHkn4qIt4h6eckfTal9HZJn939OwAcJ+xfAPbMFkkppcsppS/s/nlD0ouSnpD0Hkmf2G32CUk/8ojGCAB7wv4FYD8e6hu3I+JZSd8t6U8knU8pXd596oqk8wc7NAA4OOxfAB5WcZEUEYuSflvSz6SU1u9/Lt371cyN32IVEc9HxAsR8cLtrc19DRYA9uIg9q+7O+xfwJtNUZEUER3d22B+LaX0yd2Hr0bEhd3nL0i61vRvU0ofSSldTCldXB0uHsSYAaDYQe1fKwP2L+DNpuSn20LSRyW9mFL6pfue+pSk9+/++f2SfvfghwcAe8f+BWA/SnKSvkfSj0v6ckR8cfexD0r6sKTfioifkPSypPc+khECwN6xfwHYM1skpZT+SNKDYqG+/2EOFpHUM0F7FxZ9MNRKQQDawkr+1L78Z74+nEz9ca5v+08sNwu+lWHY8v3MJ77NziAfSlbJB1Ju7vjjPN334WbDoQ9nbBWEer56w4exfdvaOPv8Tu0D0iYF1/LVdd/m+sQHCm7O/HjaBZ+G13X+Ory67ueufuDt/f/rmSjAUUHw3lE4yP0rpdBolr9/rmz2bD/bBUGsd03o62N9P99tv8SkgjDExYIvpXvh94NRQbhsZYIgXViuJI2Tfw1Z7Pk2bz3lj/Xahr/ek5k/73UTOFkV7AVnC/bkhZnvZ9j2512QE6mVgjnumte9jYLQyllBkGmnyvfzx3cefF8fz50NAADgiFEkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA1KErcPTpJqky9VT3wgVtQ+yiruTrPPPzv0QVdrq/mAQkn6dj9cbReEFKouCIpM/nKdGubPe9D253TlZt+2SQXBcCur+bFI0qm2b/P0Y37MUxM6dulVP7+rfT+Wb2/7MM7/ul0QiGpCP6V74YXOtMq3WTldcD8VBAFWG/mAueFfFdwIJ1wrkl0j37lWcl39sUYmJLQuWBuTqV+rs3lBiG3Bvd7t+jW/4IejtgmTLMj31UpBQO3m2O+lN7f9seYFy/6JYUHIowlZfnnLJ5D+w7f6Nu2Bn5uq9m3mBfP36nWfZrphQmiv+61fnfBreGCGm7sneScJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0OBwwyQrqermg6pafR9k1SoISQsTztXv+uCtTsHsjAvC2FrtgvBL30SDgtC/jgkuWx/5uat8BpgWWj54sT/3c9wqOKdo+TVxfXMh+/xqx1+ntaEfb1X5sUxmvs20a5so+VxCLSzk56/d8iF/M/k1MU/5fgoy/k68djvp9Kn8uu887u+L7VFBcOzEzHdBwGM99ffWbObbtHYKUiCTP6eNqR/zsJNvU/JV/bQgDLFnXh+ksjX92HJBAO3Tfl/p9/Lj2fxGz/ZxquC1c2dc8Frktww9dqYgjLnr5+bla/nzGmz6F+E7Y3/e27P8eOtMmiTvJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaHGqYZKsjLT+ZD346veET9Ca3RrZNZULJNtsFIZDygVkLfdtEMfBtWma8kjTe8v0sLJnQrDM+xXDzTkGM2o4PSOud9uc0TX4JpoIwzvOP56/n7OVt20dvwV/v00t+LJOdgq89CgInt277fhb7+evQ6/vQvKpgDU/r/Hm3CwI/3wiiMuusIIG2ZNMdmkvfq/1abfV8mF+rILH0TM/vGeOCoMjNqT/zXju/XlNBeG9/2e9Nw6Gfm6HZSyUpVLDHjf2Yu1X+vE+1fZjkzcv+Os2SH+9Sx5/3yxu+n8cf37Ftzj8xzj5/epJ/XpLm/lJK0/w1+L3bhEkCAAA8FIokAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0OBQc5Ki3VJ1einbZvisDxVaOO2zE6LfyT6/uORzc2qTiSJJ822fKZGmPkOmtepzMDQpCIQY5LMyqkV/nMErG7ZNtPzcDJ4tCOAZ+XNKM597Uq3kl/J04K+TFnzOSF2Q49UqCO6IpYK8l4Ixt6r82ho80bJ9zK/7+6ltgnsqM443gkhJ7Vn+2nY2/FxWs4JMoXF+Pd+d5vc3SUrhr8kza34f7Ld8Ll1J/k5vy+89rZbJSbI9SGeG/h69s+3n7+UrQ9smfAyZlgvyqpba+TNbbvs+qoI9eWLyziRpbeDX8J2Jn79XLvvrfWeSH3PBElY7/Dn1TZN5Zl7srEbEUxHxhxHxtYj4akT89O7jH4qISxHxxd3/ftiOFAAOEfsXgP0oeSdpJulnU0pfiIglSZ+PiM/sPvfLKaVfeHTDA4B9Yf8CsGe2SEopXZZ0effPGxHxoqQnHvXAAGC/2L8A7MdDfeN2RDwr6bsl/cnuQx+IiC9FxMciYvWgBwcAB4X9C8DDKi6SImJR0m9L+pmU0rqkX5H0NknP6d5Xar/4gH/3fES8EBEv3LzrvyEYAA7aQexft7YLfsM0gDeUoiIpIjq6t8H8Wkrpk5KUUrqaUpqnlGpJvyrpnU3/NqX0kZTSxZTSxdMr+Z9sA4CDdlD719qC/2knAG8sJT/dFpI+KunFlNIv3ff4hfua/aikrxz88ABg79i/AOxHyU+3fY+kH5f05Yj44u5jH5T0voh4TveiK16S9JOPYHwAsB/sXwD2rOSn2/5IUlPS0qcf9mApSdNZPtxua9sH+s1HPiCvNcmnfE1u+wCqatmPper6wL9IPgyxnvjUrDTyY2738m8Oppavi2fDBdtmeteHm9WbBce66edvsuE/Fe4O8+OpOj78rOoWfM3Q8WtvNChIQCsIQEs9n1TXVX7+UsG3AY62fYDraDN/DWbz4xnef5D7V9UPLf2d/J5wfuaD+CbX/H4w2cw/X5esn8q3WVzzaywVfFdGmvr7+PzIh1LWJpSy6hbsgQVj6dzybRamBQGOBWmH/baf4/4g3+ZU3wdkjgoCHuvaj2Vt2a/hxyu/D04XfJjkbJS/DpOC18XpuCD0eZpv0/vLB8/L8dzZAAAAjhhFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCgJHH7wEynoSt/nQ+8uvG1NdvPzGexqVXlQ6im03O2j+7EB5dNkw+7qmvfpioIhyvIAdPyTn5y6qu+j/WRD9Ecz/w5LU99m4nPa1NBppt6Zjyp9vM7uOUnuE7+64r1iQ9aK/nqJMnP36IJM51v+j62Jn4bCLM+t8MHx510daer7QsXsm3u3vLpnRsTH9a3vZCf7zr8Wu2ZPVCSFhf9fTFKfj3PpwXhlssFe5zy57W46s+pN/FBkRtL/g6cFgSkFu3tfvq0dj5/3lXJhjEvCEguGO+NggDHqlcQ6Lzq22z+df5abU38iY8KXmems/xxpt0Hj5V3kgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANIhWEIR7YwSKuS3r5vofOSLpxaAPYv5M2XunkjZnxPlqParzPpJTOPoJ+j42G/Uvi+j9qjPfRYrz3PHD/OtQi6W8dPOKFlNLFIxvAQzpp45VO3pgZ76N10sZ73J20+WS8jxbjfbSOYrx83AYAANCAIgkAAKDBURdJHzni4z+skzZe6eSNmfE+WidtvMfdSZtPxvtoMd5H69DHe6TfkwQAAHBcHfU7SQAAAMfSkRVJEfHuiPjziPhGRPzcUY2jVES8FBFfjogvRsQLRz2ebxURH4uIaxHxlfseW4uIz0TE13f/v3qUY7zfA8b7oYi4tDvHX4yIHz7KMd4vIp6KiD+MiK9FxFcj4qd3Hz+Wc5wZ77Gd45OE/evgsYc9WuxhexzHUXzcFhEtSX8h6QckvSbpTyW9L6X0tUMfTKGIeEnSxZTSscyUiIjvk7Qp6f9IKX3X7mP/WtKtlNKHdzfy1ZTSvzzKcb7uAeP9kKTNlNIvHOXYmkTEBUkXUkpfiIglSZ+X9COS/oWO4RxnxvteHdM5PinYvx4N9rBHiz1sb47qnaR3SvpGSumbKaWJpN+U9J4jGssbQkrpc5JufcvD75H0id0/f0L3Ftix8IDxHlsppcsppS/s/nlD0ouSntAxnePMeLF/7F+PAHvYo8UetjdHVSQ9IenV+/7+mo7/Bp4k/UFEfD4inj/qwRQ6n1K6vPvnK5LOH+VgCn0gIr60+1b2sXjb91tFxLOSvlvSn+gEzPG3jFc6AXN8zLF/HZ5jf381OPb3F3tYOb5xu9z3ppT+vqQfkvRTu2+1nhjp3ueqx/1HGX9F0tskPSfpsqRfPNLRNIiIRUm/LelnUkrr9z93HOe4YbzHfo7xSJzo/Us6nvdXg2N/f7GHPZyjKpIuSXrqvr8/ufvYsZVSurT7/2uSfkf33nI/7q7ufq77+ue71454PFkppasppXlKqZb0qzpmcxwRHd27WX8tpfTJ3YeP7Rw3jfe4z/EJwf51eI7t/dXkuN9f7GEP76iKpD+V9PaIeEtEdCX9mKRPHdFYrIgY7n7jmCJiKOkHJX0l/6+OhU9Jev/un98v6XePcCzW6zfqrh/VMZrjiAhJH5X0Ykrpl+576ljO8YPGe5zn+ARh/zo8x/L+epDjfH+xh+1xHEcVJrn7Y3v/RlJL0sdSSv/qSAZSICLeqntffUlSW9KvH7fxRsRvSHqX7v2W5KuSfl7Sf5D0W5Ke1r3fXv7elNKx+EbDB4z3Xbr3FmqS9JKkn7zvs/IjFRHfK+k/S/qypHr34Q/q3mfkx26OM+N9n47pHJ8k7F8Hjz3s0WIP2+M4SNwGAAD42/jGbQAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAAN2vv5xxHxbkn/VlJL0r9PKX04136xv5jWFteyfa6vb9njVgW13aiemz7C9rHU9tMzrm0TzZJvNE9j22a53bNtJnX+vKpIto+duW8j+TbL7ZZtM639tZwlf6xJGmWfH7Y6tg8l36aKmW1zfXLHH0r59SlJa51l22a7nmafn9V+7XWrrm2zaK7l3emWduZjf1MdMw+zh3W7vbSwMMj2d/fuesFRS+4vAIcppdS4f+25SIqIlqR/J+kHJL0m6U8j4lMppa896N+sLa7pf33P/5Lt9/d/70/ssfuxYNv8xdZG9vlBy784/7PT522bv9z0G971aX4sknR39rJt8z+cfZtt81fb+RezpY5/cf5/7+zYNiootv7Z2RXb5sqOv5Y3p76AfHnnL7LP/zdrj9k+0uycbdNv37Rt/v2r/8G2GdX+i4H/8bH/zrb5L+uXs8/fGG/aPp4ZPGvb/JMz+Wv5a6/8vu3juHnYPWxhYaDv+753Zfv8j//x0/a4qaDoB1Cq4J0K+8bKg7/43c/Hbe+U9I2U0jdTShNJvynpPfvoDwAOE3sYgKz9FElPSHr1vr+/tvsYAJwE7GEAsh75N25HxPMR8UJEvLA58m/9A8Bxcf/+NZlMjno4AA7ZfoqkS5Keuu/vT+4+9jeklD6SUrqYUrq42F/cx+EA4EDZPez+/avb9d/gDuCNZT9F0p9KentEvCUiupJ+TNKnDmZYAPDIsYcByNrzT7ellGYR8QFJv697Pz77sZTSVw9sZADwCLGHAXD2lZOUUvq0JP8zr6+3V2g0z/+I+jz1bT9z+fyd5Vb+R8t7le9jNPNvtBUkCeh01/+Ye6/K50dJ0vbMj3lem6wf97yk5baPu+mEP/Hp3H+8Oii4lqda/kemr7by+TXjuR/vcsuPZX3mf9x0WvsspQdEcvwNG1PfZpryY+4WrPNuwXlvTfNbxbzgfI6jh93DnAg/D4cXAVByHD/eKGiTyH7CtziIe+FeSofro3hIe0LiNgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKDBvsIkH1YV0kI7Hw41rHyY5KDytd2klQ9NXDDPS1IrfJszvommyU/zTP73QvUKQh4HrXybpY4P51rt+PntFASFdQqW10LJCjSBiZLUneQ7qgvCL7sl4WcFwXoqClHzoZQK32atvZJ9/nbtfynramdo28zstTyZYZIPJxRmHVVR8PvdYm6b1GlaOqh98kl8VeU3uXlBgGpZuOVhOZigzSr8Bpbk7+Oi/aDgSF5BeGhBgGNJgmNV0M885e+Fsj783Lmzzu3rvJMEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaHCoYZKzWro9cm38kNoF4WZrnXzYVbcgXHBe+zbLBQGP09qHXb029v1c3/FzM5/3ss+PZz4E7HzPB3il5OemJHhxse3H0y4ILmub4M+dqR9vb8E20aXNbdtmZgLSpLLYtztTP3/jef5aDVr+vActP5o74/zzBcvqDSAUys93p10QzDkzm6Cken5YYZJ+jbUqf2PUacu2SakkcPJkqar8fnuP3/9nc7cmDu8GKwvI9HtcFIQxhwnMjYJw1igIZ3XnNK8f3AfvJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANDjUnSQqFyScaVD4XoeOjPbTYzR9noSA/ZqEgA2lY+fyKiY/J0GLL5230Kn+5OuaSLhRk4ix1/IBT8nNTcp1aBW1UkFd1qpXPp+kVrKtWFAym8mNpFWSnpJIcnOTzqmYp30+nYLztqm/bzOf5NvGm+HorKZm8mkj+Ho3D3nazCu7jgpyk2XzHtnkjRml1K5+LNU8T22Ymn53llWymXqsgm6iW37+61cC2Gaf8a02noI9k9kBJapt+6vrBQXBvhp0NAADgoVEkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0ONdWsFdKiOeITg4IwNhNAJUlhgrUWCsrDQZTEn/kAryp82NVyu2PbLLV8uGAyQ17qzG0fJodTktQpmJtW+Os0LQiKnLuTkg/aXGz5gLRJ7a/lIHxQZKugTR3bts1Sy98Ldb2YfX4Sd2wf3cqvveVefv7aJUGcJ1woVEX+Hlxsrdp+ZuGDA2/N102LgoTaAiVXrSW/75y8q+9HXBKQ2isIk0zJByJOtZF9vpbftw9KJ3y47Kygn0oFe6UeHOIoScNqxfZRz/395K7TNB58v+2rSIqIlyRtSJpLmqWULu6nPwA4TOxhAHIO4p2kf5pSunEA/QDAUWAPA9CI70kCAABosN8iKUn6g4j4fEQ8fxADAoBDxB4G4IH2+3Hb96aULkXEOUmfiYg/Syl97v4GuxvP85K0Olzb5+EA4EBl97D796/BYOGoxgjgiOzrnaSU0qXd/1+T9DuS3tnQ5iMppYsppYuL/aX9HA4ADpTbw+7fv3pd/9M6AN5Y9lwkRcQwIpZe/7OkH5T0lYMaGAA8SuxhAJz9fNx2XtLvxL18lLakX08p/acDGRUAPHrsYQCy9lwkpZS+KenvPcy/aYV0ymT67XR8cFmJaZ0PW3OhlpK0XBC8OE0+lGx75t+wa4Uf0KDjj9UzIWkrBeddVT6oLhWEsXVbvp+Rz9nUtPLHWm7nF9Zi26+r1a4PrTw99d+Xstj2AWgbace2GRZc74VO/iPsG9OCj7hTQWheO38toyh49XjZyx7mQmq7lf9ILtU+ii+Un8+y2S4JTPRt+uHDEHcKAicPJg7xYAJ+S/op6aUTPoi1VRDWuhHmHkyHFyY5qPz1Htd+/krmZmbOuyS8d1T5tbdQ5UN3tzMfqhEBAAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGiw319w+3AHayWdWcqHYu30fWjWvOWDrNa388/XBUlhK4s+9G02LghRS77NUtsHeD112p93GudD/zo+30s7O35yZj4nUqf6PimyXRCiuVMQXNY1gW0X8lli99r0/PVOAz+Bf7x+3rYZ1eu2zdqiP+92nZ+/jS0fxtYpCOs8s5wfS/tN8OVWKNQyoYmn2v6XeG8VBC/eNPtKkl+rZfy1X2r5QNKNgsDE6dwHqJbGZB4OPzeL1bJt06n6ts0Nsw/OU0Hq7gFxe6kk1TKp0JI6lW9Tzc3GEf4aVAX3U8eEUgZhkgAAAA+HIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABocKhhknUtbZugwmFBeNRLmwWhisqHUi4UBOjNRn56WgVl5qDlAzJLxrNx14/nyYV86Nhfb/jjtCs/3igIyEwT36ZXEAxaFcxxmufn5va2H8uZjg/ou3LHB60tVD5QsFsNbZubGz4IUil/PavKp34uFITdXbudbzNzoXBvBCFF5NfrIHyAnlo+ODbCzKe57gep1/L3TisKUmpPWFBkwUuR1rr+WrYrH8bZ3snP31QlQZwHo1cQJhkFAY79gnU+muf3uEHBPrlV+X1yYMZSZS72m2BnAwAAeHgUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAECDQw2TlKR5nU/o2vE5hloqKO3aVT7satgpCaT0QXwlZeagIHFyWHAlUkEY22yen99BwXj7vYKgzXlBCKQJ3pOkTkFi20rbT85pl+FXMJaU/ORsz3w/LS3aNr22D5xc7fljLVb5kLRr83O2j2HPB8Ntbru5Obxww6PUMue50lmwfXRqv846rXyI3nx21/ahgv2r5KoNKh+Q2Wv7wMTt+YZtU6d8GO7BBVL6fqJgdvotPzdLnWXbptdZzT4/rn2YpJ87qeSK91oFIcoF5z1s+ZDH7Tq/bh7rn7Z9bNZ3/Fja+fupigfvgbyTBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAYUSQAAAA0okgAAABpQJAEAADSgSAIAAGhgU6Mi4mOS/rmkayml79p9bE3S/ynpWUkvSXpvSul2yQHDhPqtLcxsH/WWr+1arXxoVrflw8QWCgInS0IKxwWBiZPk29R+atTJZ2ZpsfIBc+2OH8u4oL5uFczNrCBYb6cgwHFuwuHSvODrgYIJHhe0GdVj2ybV/jrMCsacMiFoktSqfaDbhs+p091J/rzn6aBC/g7eQe1hce/fZY91qpMP95SkYfLhgkvdx7PPzwuCA6fzLdumYGvSWtcHZK7radtmpx7ZNqPpzezzZYGJh2e51bFtVlp+/nqVCTus/HHquZ+bkvDQYUFQZBU+5HGp4F6YpPyxBm0/d8O2v59WTKBna59hkh+X9O5veeznJH02pfR2SZ/d/TsAHEcfF3sYgD2wRVJK6XOSbn3Lw++R9IndP39C0o8c7LAA4GCwhwHYq71+T9L5lNLl3T9fkXT+gMYDAIeBPQyAte9v3E4pJWV+W2BEPB8RL0TEC+s7m/s9HAAcqNwedv/+NRr776kB8May1yLpakRckKTd/197UMOU0kdSShdTSheXB/63owPAISjaw+7fv/q9/qEOEMDR22uR9ClJ79/98/sl/e7BDAcADgV7GADLFkkR8RuS/h9J3xERr0XET0j6sKQfiIivS/pnu38HgGOHPQzAXtmcpJTS+x7w1Pc/7MFCUruVz4ep2j6HptPxb4ANzJn1uj7XpZLPsumYPCZJGs1LMnF8NsWFRT/m/mCSfX469nMXbX9O/YLr1C6IzplNfaN2lc8CkqSRGc7jJj9Kkt5yOj93kvTajs/tuDp+zLaZyx/r3MB/vHO+n5+//tTnqyz1/fVe28yvm14+3uZIHegeFvl5WO74+zjmPtflVPvJ7PM7BRlI87okN8fff4OW3zMWq1O2Tbdasm0m1d3s8/W8ICyu4JxKlGQKLbbtS6jOdPy3mZxr53OmxrXfLzbTX9s2dfLfV7dckJN3qv2EbbNQkCE1rvP3y1sGa7aPSH5zX2zn13BnnzlJAAAAbzoUSQAAAA0okgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADn4R1gKoqabmbD1YcVz7IanviazsXLriS5raPXteP5faODzqcFoSbnRn6NittH0qpOj+eUUGYpGYlQZt+bpY7fo5VcB225/5Yi518cNly389dt++D6gYFCZmt8CF+BRmkWvK5hOpnQtAkaWc8sH2MfU6d+im/VaSi6L2TL1L++nfDr49ZQThqhNmaw893FLQpCV7sFmwZg/CLtR0+HLVl2szl762kksDJgvkr6KXnL6WGBWGcvVY+ELHXWrF9jFr5IE5Jms783GzO/F45Tz49diYfJjmr8+GW2zO/f01MH5K01j6bfb6VCYnlnSQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAg0MNk2yFtGTCJM+dKQni8wFoLiOtZ8YhSQst3+bskm9z65ZPHLtz1TZRb+CDF88MTDLg3Ie+zUoC5gpWTtQ+jq3T9ee0U5BJeWtkxjz316lnggIlacnno+nbFlZtm/64Z9sM2v5e6Lfzk7PY9l8HjWvfpq7zxymYuhMvJLVMQONywXwPKr8WV9bz4YF3W2dsH6ntgwNTvW7bnB74m30292t+Y/4dto3M3n43vWy7mNdj2yYlf2+VhHGe6vjr/fTQ9/Pk5oXs89u1XzN1wTlt2hbSoO0DHM92/PU+P/DnPa/zr0eP9ZdsH5M6H8R5byz5NdzJXGveSQIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0ONQwyXkK3Z7ngxXXt/2QvnnHt+mZJt0dn343bPk269f9WIY9H/I1LAiK3E4+lHK7yqcdXiqY33ntz7vT9m36BcGL81FB0ObEB6k9u5oP0ewk//XAtU0/lle3/Hlf2jGBnpLuJh/rFj0/nsVhvs25gkC80yt+fi+9lg99K8hQfAMIVWY+V3p+faS5vyapyrfphg/8m9Vbtk0kHzhpckTv9VMQQDtOfjwz5cdTEpiYCs4pya/5Et2CUOJO+Juja96v6Eff9jFsnbNtZvW2bRMFZcE8+TW8NfH7V2325UnB4hvXJWvCndOD1++bYmsDAAB4WBRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAObGhURH5P0zyVdSyl91+5jH5L0P0u6vtvsgymlT7u+qippcZAPHVs87cO5el0fHtVqmzC2jj9Ov/Jtxhtj2+aVGwu2zc0NH+B19jEfUri8mJ+bp1f9Oc1nPihsuODD45aGPtRt6k9Jf3XDB+e9cjsfdniu7897febDz5Y6BefdKQhAKwgUHG3mz0mSLu3kEzuv+Pw+fe2qH+9KO3+hZsnPy1E5sD0skqoqP1fLC37Nt6f+2p9tLWafH1VnbB+z7lttm0l927apNLRt5vJ78vb8pu9nng9ZjYJwVEXBWjyg5dpuFeynBffGxARg7szXbR87BfM7LQiTLAlRfra3atuc6tkm6qaV7PNPDP1YZnP/+nqqnd/bW5nAz5J3kj4u6d0Nj/9ySum53f9sgQQAR+TjYg8DsAe2SEopfU7SrUMYCwAcOPYwAHu1n+9J+kBEfCkiPhYR/r03ADhe2MMAZO21SPoVSW+T9Jyky5J+8UENI+L5iHghIl64s+1/qScAHIKiPez+/Ws0Hh3i8AAcB3sqklJKV1NK85RSLelXJb0z0/YjKaWLKaWLpxby34wIAIehdA+7f//q9/xvYgfwxrKnIikiLtz31x+V9JWDGQ4APHrsYQBKlEQA/Iakd0k6ExGvSfp5Se+KiOd07wcpX5L0k49uiACwd+xhAPbKFkkppfc1PPzRRzAWADhw7GEA9sonGB6g+Tx0dyP/Cd+Nl30C1Tdv+U8JZyaDqt/2AXpvXfXBcAOfP6iFgkCsJ8KPp5r7fq7cyAcQ/sV1f8nnPh9NrYIPai8s+kaDjg+H6xcEtp1byl+rTu3nriV/Mevaj3ec/LWcJX9O7bZvs9jNn1e17c8pUsmn7gWL4s0g5a9/VbA+WgXzPajy+2Au/O513cqH7I3rG34sXX/tV2Y+8HWhdcq2GaV8+um03rF9pIL7b558+GVVEFxZsn+dW/TjeWY9f6025o/bPrpzHz57s/JtHlvy4aGrlT/vlW7BXjnNvx6l2l+nrdonErdb+fspMgGk/FoSAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQINDDZMMSS3lA6Y6HR9c9u1nfDDgaJxvM1zwfSwXhBhe3+zYNqnnQ7VmBWGSZuokScu9/Ji/67wP52oVhIDNZn5u+gVhiDfu+iV4dce32TChY4+1faji1GeH6ubUX6dXRuu2za25D/G7Mz1n2wyq/PpbXPK/uf4dTxWEDt7Jr4n+5YLFecKFQmECR6vk12q/IJzRhR2O0rbtY5Q2bJtOy4cLPrnkv5ZeTEu2zY2db7NterGSff56+NDKu9NXbZvJ7I5tU2I68vN3V/414sY4H4h4ZXrF9nFnfs222Zxdtm12Jn4/2On418/uzO+VUxPOujbwx/m2uQ+/PLeQv5/amSXOO0kAAAANKJIAAAAaUCQBAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAg0PNSaqTtDPO12Vpp6Cfls9fcEkktY8q0Y0dn60zmfl8mKvrvp8rY9/Pd6wUnPcsP7911+dOtJOfnG7l2xR0o35BLtbGbV/L/+Vmfo4XTvnjDFr+GlTJX8uB8lkvkqTks5RuTvx4zuYCPiSllp+7We3XRG3yTJLv4sRLkpL5unI29+tjbOZSkrZNDlKED/UaF2QBtSKfz3OvkT9Wp/ILoFP5tTis8rlDN5IfSxX+GrRbPgsoks8Y6w/8eBZ7vs3A5LittpdtH9vprh9L56xts9L3c3PBx1WpVft8qI1J/rzvbPt75U5Bdl3H5AdG5jC8kwQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABocKhhkpKkyIeOzUwYoiR96Zof9tzESS4UlIfP+PwuPbYytW1aBbPc3fGhWStt36ZnzuuLVwsCvgoCMhd9XpueXPRz8/gpH7T2HWfGts143ss+f2bRh+Y9e94f5+rYB629Zdy3bU7NnrVtzhUEdnbM1zmb6/l5kaQ/vmmbaC2f8adJQXDoSdeK0KK5wb79GR9st1D7++K/3T6fff7Szhnbx5XBk7bNxsyv+cW2X0MqCIWtCtbzWCbA0YRNSlKr9vffrCC1uF35vXJp6MezVhAmebab31f+euT3na3av2DN5a9la+7nT3P/AnpmrWBTyKU4Slob+vtpcsu/wNYmtFKZsoR3kgAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANDjVMMkLqtvIBU/O2D6B6ejkfSClJbZMd1S4oD5c6Psjq9qafwtWz/pzOmJBNSWrt+PHMTN379jXbhabJT047/DkNC0LUbm36VMq6YJU+bUIpl3zmm7qL/kDdgkDPlglIk2SiTu959jG/Jp5YyLdZf8mf+N2pX1fdVj6MMwrW7xtBqvPXdmqyECWp1fXzvTPPt7k19WGIt6frts1Gfce2mc7zwZaSVM8LAv0K9pVxnb+PU+3vnFnt52aefKBnVfk1fXbVtzmz5K/3hev5udmYnLZ9dDSwbW7U122bhV5BUrDf4rS+4a/VnXG+owurvo9Bp6AeaOfb5LZsu2oj4qmI+MOI+FpEfDUifnr38bWI+ExEfH33/6t2pABwiNi/AOxHycdtM0k/m1J6h6R/LOmnIuIdkn5O0mdTSm+X9NndvwPAccL+BWDPbJGUUrqcUvrC7p83JL0o6QlJ75H0id1mn5D0I49ojACwJ+xfAPbjob5xOyKelfTdkv5E0vmU0uXdp65I8h9cA8ARYf8C8LCKi6SIWJT025J+JqX0N74jMKWU9IDfoxsRz0fECxHxwt2dzX0NFgD24iD2r51RwXdlA3hDKSqSIqKjexvMr6WUPrn78NWIuLD7/AVJ15r+bUrpIymliymliyuDxYMYMwAUO6j9a9DvH86AARwbJT/dFpI+KunFlNIv3ffUpyS9f/fP75f0uwc/PADYO/YvAPtRkpP0PZJ+XNKXI+KLu499UNKHJf1WRPyEpJclvfeRjBAA9o79C8Ce2SIppfRHenB01Pc/zMFaVdKpYT6U7unHt20/V7Z9bZeqfJt2ywd8rXbyY5Wk124s2DaXrvpwrls7PhDrHz3jA9Ceemycfb5/t2P7GBWkN7YKgtZOVf57OC7NfQDaX93yH3NcNYdaavmx3L3sz2ky9W2ujv11ujH3QX+bWz6xbXs6zD4/mfvxVgXJcMvdfD+tgnC5o3CQ+5cyHb2u5S+9DbaTpH5l7tOCMMSNud93dsIHvg79Laru2H/nxtmO72hjdjb7fCv8/jVXfg+UpDoVtKl9m1HBt9lG31/vjomXnSTfx835Xdvm2uyGH8spH0D7VPeMbdMrCPCd38jfUUsFc7fQ86/lS4v5NlVm+fJrSQAAABpQJAEAADSgSAIAAGhAkQQAANCAIgkAAKABRRIAAEADiiQAAIAGFEkAAAANShK3D0xIqup8eNTmtk+l++IrPqXq8pYJUqt8iNp//4yvISczP95v3vbjvTH1wZXfPc8HjknS+lZ+zC++4oMZ/+quD6Eb137+/skTfnkNCkI9p7U/734uDUxSt2Clt3r+nPod39FC26+Jdu3Pu6p8P9HOz83pZb+unu3646yYsfT8knlDaJlru/hkwb2z4QMRZ3U+RC+Fv6518gGqJcGLSxf8PrjS8v3c2vb74GR+Kvv8eOTvm61WPpBSkkazO7ZNu/LHWljx905v4AMR21X+Pk7JX4NW+LUXUXBOBQGO54a+n97Qz81oJ//8mSf9eVcm6FaSnng836b7+Qc/zztJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAaHGiYpSWHqsoKsPi22fW13ygViFQRvtZMPqbpw3oeopYJa9LUN20SdVkFIYSc/5qF5XpIWTEChJLV8Ew0KQgqfPOdD8Vb6/mDjnXxAX7/gnE4vTW2bl28ObJtTbR+a16lO2zaL4deWW1obo4JAt3FBIN5Cvo3JPnxDiJDaZn9aGPhA0t6Cn6zT38yvxdWJD6Rcba/ZNsOCwNLFs0u2zbmCkMILt/zcXDZLfnHqz3tYL9s2s+6ztk20rts2S48V7AeP+zGf+6v8/vT0lt9TtuZ+T+kUvO6tDf1euXLOr5uOH7LOrufXRLsgSHje8gHJi0/nr0HVffBGyjtJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoAFFEgAAQAOKJAAAgAaHGiZZhTTs5cOhTq35QL/npiPbZqJ82FWrZ7vQWscHHa5v+8SsbvKBWKtdHzC3aOZOks6ezs/ffLpj+zh/zi+LkB/v+QU/f+3Kn9NGy9fyK0N/LKdXEFp5ZskH4j276cPjbhaEAZ5e8ev8mbP58/7mjaHt45Utf06PnzIpf/HGT5OMCLVb+XtjYcHP5eLc73ELJiCvU/sAvaWC4MCxfJvJTR8U+epNv57/7+t+bv58+3b2+b+c/JntY316xbaZ1v7eWikIw221/Lrvrfn9dHE538/CTX+cftFbHr5RFITLprFfw9OuD9pcWMivrUWfj6nBTR+6O72U3yfT5MHj4J0kAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoMHh5iS1kgan8lk0vY7P0mgX5NlcuZLPEZkU5IOceofPi7h807f542t+mq/NNm2bv/MPfD/jaX5u1uWzK/6vP/PzO0o+Z+R/+kc+2+MtS37+qoJavjfMX8/Bou+jXfvzfsuKz4xZWdywbe7c9etv7Ywf86W7+TZ/seEzRO7O/bWMx8x5d974OUmV2hpW57Nt6tFV20/d9de1qvJtxgXZa5NUkGVT+fUx6CzaNqPar+du+HC6RZObttZ+3PbRDp9dN0n+vE91fBbV5LI/1mbL31/X7uaP9YW7d20ffz32GXi3a783rdc+W219tGzbzNf9HN+6nX9Nm4R/fbhy0zbRYiffz3z24Oft3RoRT0XEH0bE1yLiqxHx07uPfygiLkXEF3f/+2E/VAA4POxfAPaj5J2kmaSfTSl9ISKWJH0+Ij6z+9wvp5R+4dENDwD2hf0LwJ7ZIimldFnS5d0/b0TEi5KeeNQDA4D9Yv8CsB8P9Y3bEfGspO+W9Ce7D30gIr4UER+LiNWDHhwAHBT2LwAPq7hIiohFSb8t6WdSSuuSfkXS2yQ9p3tfqf3iA/7d8xHxQkS8cGtra/8jBoCHdBD719Zo+7CGC+CYKCqSIqKjexvMr6WUPilJKaWrKaV5SqmW9KuS3tn0b1NKH0kpXUwpXVwb+u+aB4CDdFD717C/cHiDBnAslPx0W0j6qKQXU0q/dN/jF+5r9qOSvnLwwwOAvWP/ArAfJT/d9j2SflzSlyPii7uPfVDS+yLiOUlJ0kuSfvIRjA8A9oP9C8Celfx02x9Jakpa+vTDHizaoc6qCR077T+Se2bVB/qdOTvJPj8a+ZCqVssH5L285T+x/IvtO76fyTdsmxe++e22TXcnH/LVKSiLL439915cG/mgsKde8mFsi/+VD7d87O/4a9WTWRMjH1Larfy66ta+zalnfZvtm35tXd/w98J/fiV/Xl/aetn2UScfBPjll/Ntdsb+nI/CQe5fLbW1XK9l29x9xSfbbfgcSL26mW80Vn5/k6RFn3OoftuvsY1LftP42iV/rKsTv6+0qvx6fvsgH+YpSeP6jG0zd/uFpL4J9JSkyXUfkHl55u/1r5v94ObEB4P2Wn6ffLydX7+SdKbj9wPNChZxVRAUbJZWf+ivU6vnxztYzl/L3KXm15IAAAA0oEgCAABoQJEEAADQgCIJAACgAUUSAABAA4okAACABhRJAAAADSiSAAAAGpQkbh+Yut3W9rnT2TY7lQ/NShMfMJWm+TbzsQ/42r7t26xNfZDVtz3mg9+Wpz5U8UrvlG2zsJzvp679OZ1d8QFzp+X7udPu2DZfLQgyfO5J36aq88FlOzf8NdgpCJxMc/91xWzog9am8m1utvz8bT2dD+h79nF/ndrhfyfZprkE85KU0hMudaT54/k235ies/20kl9Dl992J/v81viG7WNeEDgZlQ9DfHn1GdvmatffO5MLl22beRrlny+4b5R8m6rg/YGq5df0jcf89R63/N5+6S3569l67Lbto5YP+O1U/l6/fdqf0ysdH0rZ80tLd5fy+3Zr0fdx83G/zl8Z5jewSeZa804SAABAA4okAACABhRJAAAADSiSAAAAGlAkAQAANKBIAgAAaECRBAAA0IAiCQAAoEGk5MPmDuxgEdclvXzfQ2ck+VS04+OkjVc6eWNmvI/WoxrvMymls4+g32OjYf+SuP6PGuN9tBjvPQ/cvw61SPpbB494IaV08cgG8JBO2nilkzdmxvtonbTxHncnbT4Z76PFeB+toxgvH7cBAAA0oEgCAABocNRF0keO+PgP66SNVzp5Y2a8j9ZJG+9xd9Lmk/E+Woz30Tr08R7p9yQBAAAcV0f9ThIAAMCxdGRFUkS8OyL+PCK+ERE/d1TjKBURL0XElyPiixHxwlGP51tFxMci4lpEfOW+x9Yi4jMR8fXd/68e5Rjv94DxfigiLu3O8Rcj4oePcoz3i4inIuIPI+JrEfHViPjp3ceP5Rxnxnts5/gkYf86eOxhjxZ72B7HcRQft0VES9JfSPoBSa9J+lNJ70spfe3QB1MoIl6SdDGldCwzJSLi+yRtSvo/UkrftfvYv5Z0K6X04d2NfDWl9C+Pcpyve8B4PyRpM6X0C0c5tiYRcUHShZTSFyJiSdLnJf2IpH+hYzjHmfG+V8d0jk8K9q9Hgz3s0WIP25ujeifpnZK+kVL6ZkppIuk3Jb3niMbyhpBS+pykW9/y8HskfWL3z5/QvQV2LDxgvMdWSulySukLu3/ekPSipCd0TOc4M17sH/vXI8Ae9mixh+3NURVJT0h69b6/v6bjv4EnSX8QEZ+PiOePejCFzqeULu/++Yqk80c5mEIfiIgv7b6VfSze9v1WEfGspO+W9Cc6AXP8LeOVTsAcH3PsX4fn2N9fDY79/cUeVo5v3C73vSmlvy/phyT91O5brSdGuve56nH/UcZfkfQ2Sc9JuizpF490NA0iYlHSb0v6mZTS+v3PHcc5bhjvsZ9jPBInev+Sjuf91eDY31/sYQ/nqIqkS5Keuu/vT+4+dmyllC7t/v+apN/Rvbfcj7uru5/rvv757rUjHk9WSulqSmmeUqol/aqO2RxHREf3btZfSyl9cvfhYzvHTeM97nN8QrB/HZ5je381Oe73F3vYwzuqIulPJb09It4SEV1JPybpU0c0FisihrvfOKaIGEr6QUlfyf+rY+FTkt6/++f3S/rdIxyL9fqNuutHdYzmOCJC0kclvZhS+qX7njqWc/yg8R7nOT5B2L8Oz7G8vx7kON9f7GF7HMdRhUnu/tjev5HUkvSxlNK/OpKBFIiIt+reV1+S1Jb068dtvBHxG5LepXu/JfmqpJ+X9B8k/Zakp3Xvt5e/N6V0LL7R8AHjfZfuvYWaJL0k6Sfv+6z8SEXE90r6z5K+LKneffiDuvcZ+bGb48x436djOscnCfvXwWMPe7TYw/Y4DhK3AQAA/ja+cRsAAKABRRIAAEADiiQAAIAGFEkAAAANKJIAAAAaUCQBAAA0oEgCAABoQJEEAADQ4P8DiwEBkchhnLYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing images\n",
    "i = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221), plt.imshow(train_x[i], cmap='gray')\n",
    "plt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')\n",
    "plt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')\n",
    "plt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94943886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((209, 28, 28, 3), (209,)), ((11, 28, 28, 3), (11,)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, random_state=1, test_size = 0.05)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)\n",
    "\n",
    "#print(train_y)\n",
    "#print(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115b55ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([209, 3, 28, 28]), torch.Size([209]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting training images into torch format\n",
    "train_x = train_x.reshape(209, 3, 28, 28)\n",
    "train_x  = torch.from_numpy(train_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "train_y = train_y.astype(float);\n",
    "train_y = torch.from_numpy(train_y)\n",
    "\n",
    "# shape of training data\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53ffa774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 3, 28, 28]), torch.Size([11]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting validation images into torch format\n",
    "val_x = val_x.reshape(11, 3, 28, 28)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(float);\n",
    "val_y = torch.from_numpy(val_y)\n",
    "\n",
    "# shape of validation data\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4367224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(4 * 7 * 7, 1)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7790bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=196, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.05)\n",
    "# defining the loss function\n",
    "criterion = MSELoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3c8596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train, y_train = Variable(train_x), Variable(train_y)\n",
    "    \n",
    "    #print('!!!!!')\n",
    "    #print(y_train)\n",
    "    #print('?????')\n",
    "    #print(train_y)\n",
    "    \n",
    "    # getting the validation set\n",
    "    x_val, y_val = Variable(val_x), Variable(val_y)\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train)\n",
    "    output_val = model(x_val)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    output_train=output_train.squeeze(-1)\n",
    "    output_val=output_val.squeeze(-1)\n",
    "    loss_train = criterion(output_train, y_train.float())\n",
    "    loss_val = criterion(output_val, y_val.float())\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    # if epoch%2 == 0:\n",
    "    # printing the validation loss\n",
    "    print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "631344ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 \t loss : tensor(0.3517, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  2 \t loss : tensor(47.8389, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  3 \t loss : tensor(2.0883, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  4 \t loss : tensor(2.2992, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  5 \t loss : tensor(8.9081, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  6 \t loss : tensor(10.6756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  7 \t loss : tensor(7.9883, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  8 \t loss : tensor(4.3154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  9 \t loss : tensor(1.7754, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  10 \t loss : tensor(0.7153, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  11 \t loss : tensor(0.6666, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  12 \t loss : tensor(1.0129, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  13 \t loss : tensor(1.3154, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  14 \t loss : tensor(1.3610, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  15 \t loss : tensor(1.1465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  16 \t loss : tensor(0.7955, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  17 \t loss : tensor(0.4604, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  18 \t loss : tensor(0.2460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  19 \t loss : tensor(0.1540, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  20 \t loss : tensor(0.1196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  21 \t loss : tensor(0.1066, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  22 \t loss : tensor(0.1044, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  23 \t loss : tensor(0.1074, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  24 \t loss : tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  25 \t loss : tensor(0.1104, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  26 \t loss : tensor(0.1067, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  27 \t loss : tensor(0.0999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  28 \t loss : tensor(0.0902, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  29 \t loss : tensor(0.0792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  30 \t loss : tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  31 \t loss : tensor(0.0573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  32 \t loss : tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  33 \t loss : tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  34 \t loss : tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  35 \t loss : tensor(0.0381, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  36 \t loss : tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  37 \t loss : tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  38 \t loss : tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  39 \t loss : tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  40 \t loss : tensor(0.0580, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  41 \t loss : tensor(0.0607, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  42 \t loss : tensor(0.0616, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  43 \t loss : tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  44 \t loss : tensor(0.0577, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  45 \t loss : tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  46 \t loss : tensor(0.0490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  47 \t loss : tensor(0.0441, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  48 \t loss : tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  49 \t loss : tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  50 \t loss : tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  51 \t loss : tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  52 \t loss : tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  53 \t loss : tensor(0.0239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  54 \t loss : tensor(0.0227, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  55 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  56 \t loss : tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  57 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  58 \t loss : tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  59 \t loss : tensor(0.0203, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  60 \t loss : tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  61 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  62 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  63 \t loss : tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  64 \t loss : tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  65 \t loss : tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  66 \t loss : tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  67 \t loss : tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  68 \t loss : tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  69 \t loss : tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  70 \t loss : tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  71 \t loss : tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  72 \t loss : tensor(0.0282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  73 \t loss : tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  74 \t loss : tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  75 \t loss : tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  76 \t loss : tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  77 \t loss : tensor(0.0255, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  78 \t loss : tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  79 \t loss : tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  80 \t loss : tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  81 \t loss : tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  82 \t loss : tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  83 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  84 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  85 \t loss : tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  86 \t loss : tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  87 \t loss : tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  88 \t loss : tensor(0.0200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  89 \t loss : tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  90 \t loss : tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  91 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  92 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  93 \t loss : tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  94 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  95 \t loss : tensor(0.0220, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  96 \t loss : tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  97 \t loss : tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  98 \t loss : tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  99 \t loss : tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  100 \t loss : tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  101 \t loss : tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  102 \t loss : tensor(0.0229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  103 \t loss : tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  104 \t loss : tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  105 \t loss : tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  106 \t loss : tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  107 \t loss : tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  108 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  109 \t loss : tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  110 \t loss : tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  111 \t loss : tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  112 \t loss : tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  113 \t loss : tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  114 \t loss : tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  115 \t loss : tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  116 \t loss : tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  117 \t loss : tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  118 \t loss : tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  119 \t loss : tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  120 \t loss : tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  121 \t loss : tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  122 \t loss : tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  123 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  124 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  125 \t loss : tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  126 \t loss : tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  127 \t loss : tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  128 \t loss : tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  129 \t loss : tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  130 \t loss : tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  131 \t loss : tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  132 \t loss : tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  133 \t loss : tensor(0.0211, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  134 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  135 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  136 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  137 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  138 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  139 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  140 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  141 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  142 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  143 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  144 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  145 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  146 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  147 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  148 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  149 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  150 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  151 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  152 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  153 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  154 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  155 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  156 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  157 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  158 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  159 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  160 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  161 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  162 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  163 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  164 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  165 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  166 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  167 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  168 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  169 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  170 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  171 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  172 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  173 \t loss : tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  174 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  175 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  176 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  177 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  178 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  179 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  180 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  181 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  182 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  183 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  184 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  185 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  186 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  187 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  188 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  189 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  190 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  191 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  192 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  193 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  194 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  195 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  196 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  197 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  198 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  199 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  200 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  201 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  202 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  203 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  204 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  205 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  206 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  207 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  208 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  209 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  210 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  211 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  212 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  213 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  214 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  215 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  216 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  217 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  218 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  219 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  220 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  221 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  222 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  223 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  224 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  225 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  226 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  227 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  228 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  229 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  230 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  231 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  232 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  233 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  234 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  235 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  236 \t loss : tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  237 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  238 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  239 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  240 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  241 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  242 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  243 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  244 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  245 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  246 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  247 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  248 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  249 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  250 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  251 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  252 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  253 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  254 \t loss : tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  255 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  256 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  257 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  258 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  259 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  260 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  261 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  262 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  263 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  264 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  265 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  266 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  267 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  268 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  269 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  270 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  271 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  272 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  273 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  274 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  275 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  276 \t loss : tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  277 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  278 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  279 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  280 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  281 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  282 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  283 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  284 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  285 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  286 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  287 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  288 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  289 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  290 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  291 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  292 \t loss : tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  293 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  294 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  295 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  296 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  297 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  298 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  299 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Epoch :  300 \t loss : tensor(0.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 300\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b502de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for training set\n",
    "with torch.no_grad():\n",
    "    output = model(train_x.cuda())\n",
    " \n",
    "softmax = torch.exp(output).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "#print(train_y)\n",
    "#print(predictions)\n",
    "\n",
    "# accuracy on training set\n",
    "#accuracy_score(train_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fedf091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for validation set\n",
    "with torch.no_grad():\n",
    "    output = model(val_x.cuda())\n",
    "\n",
    "softmax = torch.exp(output).cpu()\n",
    "prob = list(softmax.numpy())\n",
    "predictions = np.argmax(prob, axis=1)\n",
    "\n",
    "# accuracy on validation set\n",
    "#accuracy_score(val_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc171fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 106.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 28, 28, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading test images\n",
    "test_img = []\n",
    "for img_name in tqdm(test['track']):\n",
    "    # defining the image path\n",
    "    image_path = './img/' + str(img_name) + '.jpg'\n",
    "    # reading the image\n",
    "    img = imread(image_path)\n",
    "    # normalizing the pixel values\n",
    "    #img /= 255.0\n",
    "    img = resize(img, (28, 28))\n",
    "    # converting the type of pixel to float 32\n",
    "    img = img.astype('float32')\n",
    "    # appending the image into the list\n",
    "    test_img.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "test_x = np.array(test_img)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf918564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 3, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting training images into torch format\n",
    "test_x = test_x.reshape(15, 3, 28, 28)\n",
    "test_x  = torch.from_numpy(test_x)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1824ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6738],\n",
      "        [0.6580],\n",
      "        [0.6488],\n",
      "        [0.6329],\n",
      "        [0.6574],\n",
      "        [0.6467],\n",
      "        [0.6531],\n",
      "        [0.6579],\n",
      "        [0.6405],\n",
      "        [0.6542],\n",
      "        [0.6071],\n",
      "        [0.6639],\n",
      "        [0.6610],\n",
      "        [0.6500],\n",
      "        [0.6703]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# generating predictions for test set\n",
    "with torch.no_grad():\n",
    "    output = model(test_x.cuda())\n",
    "\n",
    "print(output)\n",
    "\n",
    "#softmax = torch.exp(output).cpu()\n",
    "#prob = list(softmax.numpy())\n",
    "#predictions = np.argmax(prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf70f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normalize_5s_intro_0EVVKs6DQLo.wav</td>\n",
       "      <td>0.673794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normalize_5s_intro_d7to9URtLZ4.wav</td>\n",
       "      <td>0.658020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normalize_5s_intro_TzhhbYS9EO4.wav</td>\n",
       "      <td>0.648752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normalize_5s_intro_nn5nypm7GG8.wav</td>\n",
       "      <td>0.632901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normalize_5s_intro_hed6HkYNA7g.wav</td>\n",
       "      <td>0.657370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                track     score\n",
       "0  normalize_5s_intro_0EVVKs6DQLo.wav  0.673794\n",
       "1  normalize_5s_intro_d7to9URtLZ4.wav  0.658020\n",
       "2  normalize_5s_intro_TzhhbYS9EO4.wav  0.648752\n",
       "3  normalize_5s_intro_nn5nypm7GG8.wav  0.632901\n",
       "4  normalize_5s_intro_hed6HkYNA7g.wav  0.657370"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing the label with prediction\n",
    "sample_submission['score'] = output.cpu()\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aac84864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0db72bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'CNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87565e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
